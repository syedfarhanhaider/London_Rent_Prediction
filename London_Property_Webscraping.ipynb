{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4498efcf-03f1-4ca0-8c75-8409b2485c7e",
   "metadata": {},
   "source": [
    "# WebScraping Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc1a9e5-6989-447e-95a3-06598fd501ef",
   "metadata": {},
   "source": [
    "The following code is used to scrap actual data from a renowned house rental website in the UK. For privacy reasons the url is masked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4a505547-a47c-46f1-8fca-86b802a449ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.edge.service import Service\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "from webdriver_manager.microsoft import EdgeChromiumDriverManager\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "import urllib.parse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ffe6e9-9d3c-4d32-a1f2-bb5d79b154d4",
   "metadata": {},
   "source": [
    "Function to get the address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed638500-9550-4aac-9496-acb5dd697fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_address(new_soup):\n",
    "\n",
    "    # This will find the <h1> tag and the provided class from the soup that is extracted from the website.\n",
    "    # The address is in the <h1> tag because the address is the 'title'\n",
    "    address = new_soup.find(\"h1\", attrs={'class':\"_2uQQ3SV0eMHL1P6t5ZDo2q\"}).text\n",
    "    \n",
    "    return address"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52703d2f-8374-4bb3-9d19-776d5581ff28",
   "metadata": {},
   "source": [
    "Function to get the Furnish Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "009e61cf-2865-473e-bcdd-96f1e6cf72a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_furnish_type(new_soup):\n",
    "\n",
    "    #Finding the <dt> tag that contains 'Furnish type'\n",
    "    furnish_type_dt = new_soup.find(\"dt\", string=lambda text: \"Furnish type\" in text)\n",
    "    if furnish_type_dt:  \n",
    "        furnish_type_dd = furnish_type_dt.find_next(\"dd\") # Then finding the <dd> tag\n",
    "        if furnish_type_dd:\n",
    "            furnish_type = furnish_type_dd.get_text(strip=True) # Then extracting the text inside the <dd> tag\n",
    "        else:\n",
    "            furnish_type = \"No information\"\n",
    "    else:\n",
    "        furnish_type = \"No information\"\n",
    "\n",
    "    return furnish_type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9713b2-dba8-452b-bae0-2bb03eae5c57",
   "metadata": {},
   "source": [
    "Function to get the APartment type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6ac81fe-60dc-406b-b07f-0cc97af17582",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_apartment_type(new_soup):\n",
    "\n",
    "    # Finding all the dd tagged elements with the provided class\n",
    "    dd_elements = new_soup.find_all('dd', class_='_3ZGPwl2N1mHAJH3cbltyWn') \n",
    "    \n",
    "    # Iterating through these <dd> elements to find the one that contains 'PROPERTY TYPE'\n",
    "    for dd in dd_elements:\n",
    "        \n",
    "        # Checking if the sibling <dt> tag contains 'PROPERTY TYPE'\n",
    "        if dd.find_previous_sibling('dt').text.strip() == 'PROPERTY TYPE':\n",
    "        \n",
    "            # Now finding the <p> tag with the class that holds the PROPERTY TYPE\n",
    "            p_tag = dd.find('p', class_='_1hV1kqpVceE9m-QrX_hWDN')\n",
    "            \n",
    "            if p_tag:\n",
    "                apartment_type = p_tag.text.strip()\n",
    "                break\n",
    "    else:\n",
    "        apartment_type = None\n",
    "\n",
    "    return apartment_type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b5a2f7-591b-4806-82c4-2cfd9de74fea",
   "metadata": {},
   "source": [
    "Function to the the number of bedrooms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5edf2d85-1d9b-4fd5-a60e-63b147ee1407",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bedrooms(new_soup):\n",
    "\n",
    "    # Finding all the dd tagged elements with the provided class\n",
    "    dd_elements = new_soup.find_all('dd', class_='_3ZGPwl2N1mHAJH3cbltyWn')     \n",
    "    \n",
    "    for dd in dd_elements:\n",
    "        \n",
    "        # Checking if the sibling <dt> tag contains 'BEDROOMS'\n",
    "        if dd.find_previous_sibling('dt').text.strip() == 'BEDROOMS':\n",
    "            \n",
    "            # Now finding the <p> tag with the class that holds the number of bedrooms\n",
    "            p_tag = dd.find('p', class_='_1hV1kqpVceE9m-QrX_hWDN')\n",
    "            \n",
    "            if p_tag:\n",
    "                number_of_bedrooms = p_tag.text.strip()\n",
    "                break\n",
    "    else:\n",
    "        number_of_bedrooms = None\n",
    "    \n",
    "    return number_of_bedrooms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "600b4d3c-5a78-4649-b84f-3d359bd95ed3",
   "metadata": {},
   "source": [
    "Function to get the number of bathrooms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e30d745-76e8-44c0-995f-72c1dd05ed37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bathroom(new_soup):\n",
    "\n",
    "    # Finding all the dd tagged elements with the provided class\n",
    "    dd_elements = new_soup.find_all('dd', class_='_3ZGPwl2N1mHAJH3cbltyWn')     \n",
    "    \n",
    "    for dd in dd_elements:\n",
    "        \n",
    "        # Checking if the sibling <dt> tag contains 'BATHROOMS'\n",
    "        if dd.find_previous_sibling('dt').text.strip() == 'BATHROOMS':\n",
    "           \n",
    "            # Now finding the <p> tag with the class that holds the number of bathrooms\n",
    "            p_tag = dd.find('p', class_='_1hV1kqpVceE9m-QrX_hWDN')\n",
    "            \n",
    "            if p_tag:\n",
    "                number_of_bathrooms = p_tag.text.strip()\n",
    "                break\n",
    "    else:\n",
    "        number_of_bathrooms = None\n",
    "    \n",
    "    return number_of_bathrooms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4576ed7-bbad-492a-981d-4767b2303b72",
   "metadata": {},
   "source": [
    "Function to get the Rent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56dbe8c3-a3fc-47d7-b5ee-c7e0d91bdbbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_price(new_soup):\n",
    "\n",
    "    # Finding all the <div> tagged elements with the provided class\n",
    "    div_elements = new_soup.find_all('div', class_='_1gfnqJ3Vtd1z40MlC0MzXu') \n",
    "\n",
    "    div_with_price = new_soup.find('div', class_='_1gfnqJ3Vtd1z40MlC0MzXu')\n",
    "    \n",
    "    if div_with_price:\n",
    "        \n",
    "        # Finding the <span> inside the <div>\n",
    "        price_span = div_with_price.find('span')\n",
    "        \n",
    "        if price_span:\n",
    "            price_text = price_span.text.strip()\n",
    "        else:\n",
    "            price_text = None\n",
    "    else:\n",
    "        price_text = None\n",
    "\n",
    "    return price_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d98046-b67a-4fcb-bdb3-438d07802685",
   "metadata": {},
   "source": [
    "Function to check if the current page is the last page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "08188f6c-3c14-451a-9150-4b9d3304c574",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_last_page(soup):\n",
    "    \n",
    "    # Looking for the disabled 'Next' button in the parsed HTML\n",
    "    next_button = soup.find(\"button\", {\"data-test\": \"pagination-next\", \"disabled\": True})\n",
    "    \n",
    "    return bool(next_button)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a604a6f6-c841-4f40-bc81-106898a2422e",
   "metadata": {},
   "source": [
    "Function to check if the 'next' button on the page is present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "41b1829a-459b-44c0-b311-3866c624c14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_button(driver):\n",
    "    \n",
    "    try:\n",
    "        # Waiting for the next button to be clickable\n",
    "        next_button = WebDriverWait(driver, 10).until(\n",
    "            EC.element_to_be_clickable((By.CSS_SELECTOR, \"button[data-test='pagination-next']\"))\n",
    "        )\n",
    "        # Scrolling the next button into view\n",
    "        driver.execute_script(\"arguments[0].scrollIntoView(true);\", next_button)\n",
    "        return next_button\n",
    "    except TimeoutException:\n",
    "        \n",
    "        # Returning None if the next button is not found within 10 seconds\n",
    "        return None"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1497d7f5-ef68-4a1f-b3b5-54b46b409056",
   "metadata": {},
   "source": [
    "Function to get the web driver (Used to run the browser in background)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "878e728d-f424-42f8-bbde-8bd7f57ae629",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_driver():\n",
    "    # Initializing and return a headless Edge WebDriver.\n",
    "    edge_options = webdriver.EdgeOptions()\n",
    "    edge_options.use_chromium = True\n",
    "    edge_options.add_argument(\"--headless\")  # Running browser in the background\n",
    "    driver = webdriver.Edge(service=Service(EdgeChromiumDriverManager().install()), options=edge_options)\n",
    "    \n",
    "    return driver"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e3b23c-a0d1-4a56-bdb0-982f2d90f52e",
   "metadata": {},
   "source": [
    "Function to check the property cards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e79beb9f-a7d2-41a7-833e-810eacb82d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_property_cards(soup):\n",
    "    \n",
    "    # Checks if there are property cards on the page by looking for divs with the 'propertySearch' class.\n",
    "    listings = soup.find_all(\"div\", class_=\"propertySearch\")\n",
    "    \n",
    "    return len(listings) > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ac6519-25ec-44ba-b362-914bc0de5fc6",
   "metadata": {},
   "source": [
    "## Main Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5050db0e-3e8e-496b-8dd4-7f619b784f9f",
   "metadata": {},
   "source": [
    "All the above functions will be called one by one.\n",
    "\n",
    "The dataframe will then be saved into a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "13c8bcbf-2098-44cd-91d9-381387be8ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    edge_options = webdriver.EdgeOptions()\n",
    "    edge_options.use_chromium = True\n",
    "    edge_options.add_argument(\"--headless\")\n",
    "    \n",
    "    driver = webdriver.Edge(service=Service(EdgeChromiumDriverManager().install()), options=edge_options)\n",
    "\n",
    "    base_url = 'https://www.xxxxxxxxxxxxxxx.co.uk/property-to-rent/find.html'\n",
    "    params = {\n",
    "        'locationIdentifier': 'REGION^87490',\n",
    "        'index': 0,\n",
    "        'propertyTypes': '',\n",
    "        'includeLetAgreed': 'false',\n",
    "        'mustHave': '',\n",
    "        'dontShow': '',\n",
    "        'furnishTypes': '',\n",
    "        'keywords': ''\n",
    "    }\n",
    "\n",
    "    d = {\"address\":[], \"furnish_type\":[], \"apartment_type\":[], \"bedrooms\":[], \"bathrooms\":[], \"rent\":[]}\n",
    "\n",
    "    while True:\n",
    "        # Modifying the URL with the current index\n",
    "        driver.get(f\"{base_url}?{urllib.parse.urlencode(params)}\")\n",
    "        time.sleep(2)  # Allow the page to load completely\n",
    "        html = driver.page_source\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "        # Checking if there are no properties found, then break\n",
    "        if not soup.find(\"a\", attrs={'class': \"propertyCard-link\"}):\n",
    "            break\n",
    "\n",
    "        links = soup.find_all(\"a\", attrs={'class': \"propertyCard-link\"})\n",
    "\n",
    "        for link in links:\n",
    "            href = link.get('href')\n",
    "            property_url = f\"https://www.xxxxxxxxx.co.uk{href}\"\n",
    "\n",
    "            driver.get(property_url)\n",
    "            time.sleep(2)  # Wait for the page to load\n",
    "            property_html = driver.page_source\n",
    "            new_soup = BeautifulSoup(property_html, 'html.parser')\n",
    "\n",
    "            d['address'].append(get_address(new_soup))\n",
    "            d['furnish_type'].append(get_furnish_type(new_soup))\n",
    "            d['apartment_type'].append(get_apartment_type(new_soup))\n",
    "            d['bedrooms'].append(get_bedrooms(new_soup))\n",
    "            d['bathrooms'].append(get_bathroom(new_soup))\n",
    "            d['rent'].append(get_price(new_soup))\n",
    "\n",
    "        # Incrementing the index for the next page by the number of listings per page\n",
    "        params['index'] += 24\n",
    "\n",
    "    driver.quit()\n",
    "\n",
    "    # Creating a DataFrame and save to CSV\n",
    "    london_property_df = pd.DataFrame.from_dict(d)\n",
    "    london_property_df['address'].replace('', np.nan, inplace=True)\n",
    "    london_property_df.dropna(subset=['address'], inplace=True)\n",
    "    london_property_df.to_csv(\"london_property.csv\", header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fa55f951-c9ac-49a7-8160-e8975d8af11b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2100, 6)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "london_property_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d26f37e-e372-4332-8eae-bf3bcfc8b9dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
